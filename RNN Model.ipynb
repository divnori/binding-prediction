{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa68f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dec6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.22.1\n",
      "pandas 1.3.5\n",
      "torch 1.9.1\n",
      "pytorch_lightning 1.6.4\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100, \"display.width\",200, \"display.max_colwidth\",40)\n",
    "import pickle\n",
    "from termcolor import colored\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tudata\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.callbacks as plc\n",
    "\n",
    "#from binary_label_metrics import BinaryLabelMetrics\n",
    "\n",
    "for x in [(\"numpy\",\"np\"),(\"pandas\",\"pd\"),(\"torch\",\"torch\"),(\"pytorch_lightning\",\"pl\")]:\n",
    "  print(f\"{x[0]} {eval(f'{x[1]}.__version__')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d88ec",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aee081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTROL_TO_CASE: 1\n"
     ]
    }
   ],
   "source": [
    "clargs = dict(\n",
    "  #number of controls to cases\n",
    "   CONTROL_TO_CASE = 1,\n",
    ")\n",
    "\n",
    "offs = max(map(len,clargs.keys()))\n",
    "for k,v in clargs.items():\n",
    "  print(f\"{k:>{offs}}: {v}\")\n",
    "\n",
    "del k, v, offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482d8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"data/data.pkl.gz\", \"rb\", compresslevel=9) as fil:\n",
    "  data_orig_dfs = pickle.load(fil)\n",
    "\n",
    "del fil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ae6ed",
   "metadata": {},
   "source": [
    "#### Create Controls By Randomly Matching Antibody/Antigens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0fb6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtrain orig 4105, case+cont 8210\u001b[0m\n",
      "                              antibody_seq                             antibody_cdr                              antigen_seq\n",
      "0  EVQLLESGGGLVQPGGSLRLSCAASGFTFSSYAMSW...  000000000000000000000000011111111000...  PTNLCPFGEVFNATRFASVYAWNRKRISNCVADYSV...\n",
      "1  QVQLVESGGGLVQPGGSLRLSCAASGFTLDDYAIGW...  000000000000000000000000011111111000...  TNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVL... \n",
      "\n",
      "   label                             antibody_ind                              antigen_ind  antibody_sz  antigen_sz\n",
      "0      1  [4, 18, 14, 10, 10, 4, 16, 6, 6, 6, ...  [13, 17, 12, 10, 2, 13, 5, 6, 4, 18,...          227         198\n",
      "1      1  [14, 18, 14, 10, 18, 4, 16, 6, 6, 6,...  [17, 12, 10, 2, 13, 5, 6, 4, 18, 5, ...          133         195 \n",
      "\n",
      "==distribution==\n",
      "             0.02  0.20  0.50  0.80  0.98  1.00\n",
      "antibody_sz   112   121   213   222   233   366\n",
      "antigen_sz      7    90   212   442  1072  2346 \n",
      "\n",
      "\u001b[1mvalid orig 136, case+cont 272\u001b[0m\n",
      "                              antibody_seq                             antibody_cdr                              antigen_seq\n",
      "0  EVQLQQSGPELVKPGASVKMSCKASGYTFTSNVMHW...  000000000000000000000000011111111000...  PAWTQCQQLSQKLCTLAWSAHPLVDVPHIQCGDGCD...\n",
      "1  EVQLQESGAELMKPGASVKISCKATGYTFTTYWIEW...  000000000000000000000000011111111000...  KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFES... \n",
      "\n",
      "   label                             antibody_ind                              antigen_ind  antibody_sz  antigen_sz\n",
      "0      1  [4, 18, 14, 10, 14, 14, 16, 6, 13, 4...  [13, 1, 19, 17, 14, 2, 14, 14, 10, 1...          216         133\n",
      "1      1  [4, 18, 14, 10, 14, 4, 16, 6, 1, 4, ...  [9, 18, 5, 6, 15, 2, 4, 10, 1, 1, 1,...          211         129 \n",
      "\n",
      "==distribution==\n",
      "             0.02  0.20  0.50  0.80  0.98  1.00\n",
      "antibody_sz   117   209   217   221   231   238\n",
      "antigen_sz     59    97   180   323   729  1267 \n",
      "\n",
      "\u001b[1mtest orig 44, case+cont 88\u001b[0m\n",
      "                              antibody_seq                             antibody_cdr                              antigen_seq\n",
      "0  EIQLQQSGAELVRPGALVKLSCKASGFNIKDYYMHW...  000000000000000000000000011111111000...  TNTVAAYNLTWKSTNFKTILEWEPKPVNQVYTVQIS...\n",
      "1  EVQLQESGPSLVKPSQTLSLTCSVTGDSVTSDYWSW...  000000000000000000000000011111111000...  KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFES... \n",
      "\n",
      "   label                             antibody_ind                              antigen_ind  antibody_sz  antigen_sz\n",
      "0      1  [4, 8, 14, 10, 14, 14, 16, 6, 1, 4, ...  [17, 12, 17, 18, 1, 1, 20, 12, 10, 1...          214         200\n",
      "1      1  [4, 18, 14, 10, 14, 4, 16, 6, 13, 16...  [9, 18, 5, 6, 15, 2, 4, 10, 1, 1, 1,...          210         129 \n",
      "\n",
      "==distribution==\n",
      "             0.02  0.20  0.50  0.80  0.98  1.00\n",
      "antibody_sz   118   212   218   221   227   236\n",
      "antigen_sz     61   104   183   249   344   555 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "let2ind = dict((k,v) for v,k in enumerate(\"ACDEFGHIKLMNPQRSTVWY\",1)) #0 for null\n",
    "\n",
    "data_dfs = dict()\n",
    "for k,df in data_orig_dfs.items():  \n",
    "  lst = list()\n",
    "  df1 = df.loc[:,[\"antibody_seq\",\"antigen_seq\"]]; df1[\"label\"] = 1\n",
    "  lst.append(df1)\n",
    "  \n",
    "  ind1 = np.arange(df1.shape[0])\n",
    "  for n in range(clargs[\"CONTROL_TO_CASE\"]):\n",
    "    ind2 = np.copy(ind1)\n",
    "    while (ind1==ind2).any():\n",
    "      np.random.shuffle(ind2)\n",
    "    df2 = pd.DataFrame(dict(antibody_seq=df1.loc[ind1,\"antibody_seq\"],antigen_seq=df1.loc[ind2,\"antigen_seq\"],label=0))\n",
    "    lst.append(df2)\n",
    "  df3 = pd.concat(lst, ignore_index=True)\n",
    "  df3[[\"antibody_ind\",\"antigen_ind\"]] = df3[[\"antibody_seq\",\"antigen_seq\"]].applymap(lambda x:[let2ind[l] for l in x])\n",
    "  df3[[\"antibody_sz\",\"antigen_sz\"]] = df3[[\"antibody_seq\",\"antigen_seq\"]].applymap(len)\n",
    "  df3.drop(columns=[\"antibody_seq\",\"antigen_seq\"], inplace=True); data_dfs[k] = df3\n",
    "    \n",
    "  print(colored(f\"{k} orig {df.shape[0]}, case+cont {df3.shape[0]}\", attrs=[\"bold\"]), flush=True)\n",
    "  print(df.head(2),\"\\n\"); print(df3.head(2),\"\\n\")\n",
    "  print(\"==distribution==\")\n",
    "  p = [.02,.2,.5,.8,.98,1.]\n",
    "  print(pd.concat([df3[\"antibody_sz\"].quantile(p,interpolation=\"nearest\").to_frame().T,\n",
    "                   df3[\"antigen_sz\"].quantile(p,interpolation=\"nearest\").to_frame().T]),\"\\n\")\n",
    "\n",
    "del df, df1, df2, df3, ind1, ind2, k, lst, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e97447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A:1 C:2 D:3 E:4 F:5 G:6 H:7 I:8 K:9 L:10 M:11 N:12 P:13 Q:14 R:15 S:16 T:17 V:18 W:19 Y:20'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ag</th>\n",
       "      <th>ag_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVQL</td>\n",
       "      <td>[4, 18, 14, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KY</td>\n",
       "      <td>[9, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RHG</td>\n",
       "      <td>[15, 7, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ag           ag_ind\n",
       "0  EVQL  [4, 18, 14, 10]\n",
       "1    KY          [9, 20]\n",
       "2   RHG       [15, 7, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 18, 14, 10],\n",
       "        [ 9, 20,  0,  0],\n",
       "        [15,  7,  6,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "\" \".join(map(lambda x:f\"{x[0]}:{x[1]}\", let2ind.items()))\n",
    "\n",
    "df = pd.DataFrame({\"ag\":[\"EVQL\",\"KY\",\"RHG\"]})\n",
    "df[\"ag_ind\"] = df[[\"ag\"]].applymap(lambda x:[let2ind[l] for l in x])\n",
    "df\n",
    "\n",
    "tens = pad_sequence([torch.LongTensor(x) for x in df[\"ag_ind\"]],batch_first=True,padding_value=0)\n",
    "tens\n",
    "\n",
    "F.one_hot(tens, len(let2ind)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9908de",
   "metadata": {},
   "source": [
    "#### Pytorch-lightning DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(tudata.Dataset):\n",
    "  \n",
    "  def __init__(self, df):\n",
    "    super().__init__()\n",
    "    assert df.columns.tolist() == \"label,antibody_ind,antigen_ind,antibody_sz,antigen_sz\".split(\",\")\n",
    "    self.df = df\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.df.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.df.iloc[idx]\n",
    "\n",
    "\n",
    "#in:  list of pandas rows\n",
    "#out: antibody tensor, antibody sizes, antigen tensor, antigen sizes, labels\n",
    "def pad_collate(batch):\n",
    "  return \\\n",
    "      (pad_sequence([torch.LongTensor(x[\"antibody_ind\"]) for x in batch],batch_first=True,padding_value=0), \\\n",
    "      torch.LongTensor([x[\"antibody_sz\"] for x in batch]), \\\n",
    "      pad_sequence([torch.LongTensor(x[\"antigen_ind\"]) for x in batch],batch_first=True,padding_value=0), \\\n",
    "      torch.LongTensor([x[\"antigen_sz\"] for x in batch])), \\\n",
    "      torch.FloatTensor([x[\"label\"] for x in batch])\n",
    "\n",
    "\n",
    "# #test\n",
    "# dl = tudata.DataLoader(PandasDataset(data_dfs[\"train\"]), \n",
    "#                         batch_size=6, num_workers=1, drop_last=False, shuffle=True, collate_fn=pad_collate)\n",
    "# dl = iter(dl)\n",
    "# for n in range(2):\n",
    "#   print(colored(f\"==batch {n+1}==\",attrs=[\"bold\"]))\n",
    "#   dl.next(); print()\n",
    "# del dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325ea047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataModule(pl.LightningDataModule):\n",
    "  \n",
    "  def __init__(self, prm):\n",
    "    super().__init__()\n",
    "    self.bs = prm[\"batch_size\"]\n",
    "  \n",
    "  def train_dataloader(self):\n",
    "    train = PandasDataset(data_dfs[\"train\"])\n",
    "    return tudata.DataLoader(train, batch_size=self.bs, num_workers=4, drop_last=False, shuffle=True, collate_fn=pad_collate)\n",
    "  \n",
    "  def val_dataloader(self):\n",
    "    valid = PandasDataset(data_dfs[\"valid\"])\n",
    "    return tudata.DataLoader(valid, batch_size=self.bs, num_workers=4, drop_last=False, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "# #test\n",
    "# lstmdm = PandasDataModule({\"batch_size\":4})\n",
    "# dl = iter(lstmdm.val_dataloader())\n",
    "# for n in range(1):\n",
    "#   print(colored(f\"==batch {n+1}==\",attrs=[\"bold\"]))\n",
    "#   dl.next(); print()\n",
    "# del lstmdm, dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496b82d",
   "metadata": {},
   "source": [
    "#### Pytorch Lightning Module\n",
    "\n",
    "Examples Using Padding and Packing for LSTMs\n",
    "- https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "- https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129b6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "  \n",
    "  def __init__(self, prm):\n",
    "    super().__init__()\n",
    "        \n",
    "    #LSTM\n",
    "    self.rnn_ab = nn.LSTM(input_size=len(let2ind)+1, hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "    self.rnn_ag = nn.LSTM(input_size=len(let2ind)+1, hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "    \n",
    "    #LSTM output to be concatenated\n",
    "    self.fc1 = nn.Linear(in_features=2*prm[\"lstm_hidden_size\"], out_features=16)\n",
    "    self.dropout = nn.Dropout(p=.5)\n",
    "    self.fc2 = nn.Linear(in_features=16, out_features=1)\n",
    "  \n",
    "  def forward(self, ab_tens, a, ag_tens, b):    \n",
    "    #antibody\n",
    "    ab_out = F.one_hot(ab_tens,len(let2ind)+1).type(torch.FloatTensor).cuda()\n",
    "    ab_out,(ab_hid,_) = self.rnn_ab(ab_out)\n",
    "    \n",
    "    #antigen\n",
    "    ag_out = F.one_hot(ag_tens,len(let2ind)+1).type(torch.FloatTensor).cuda()\n",
    "    ag_out,(ag_hid,_) = self.rnn_ab(ag_out)\n",
    "    \n",
    "    out = self.fc1(torch.cat([ab_out[:,-1,:],ag_out[:,-1,:]],dim=1))\n",
    "    out = self.dropout(F.relu(out))\n",
    "    out = self.fc2(out)\n",
    "    return out.squeeze()\n",
    "\n",
    "#class RNNModel(nn.Module):\n",
    "#  \n",
    "#  def __init__(self, prm):\n",
    "#    super().__init__()\n",
    "#    \n",
    "#    # #embedding (adding 1 for padding_idx)\n",
    "#    # self.embed_ab = nn.Embedding(num_embeddings=len(let2ind)+1, embedding_dim=prm[\"embed_dim\"], padding_idx=0)\n",
    "#    # self.embed_ag = nn.Embedding(num_embeddings=len(let2ind)+1, embedding_dim=prm[\"embed_dim\"], padding_idx=0)\n",
    "#    \n",
    "#    #LSTM or GRU\n",
    "#    #self.rnn_ab = nn.LSTM(input_size=prm[\"embed_dim\"], hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "#    #self.rnn_ag = nn.LSTM(input_size=prm[\"embed_dim\"], hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "#    self.rnn_ab = nn.LSTM(input_size=len(let2ind)+1, hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "#    self.rnn_ag = nn.LSTM(input_size=len(let2ind)+1, hidden_size=prm[\"lstm_hidden_size\"], num_layers=1, batch_first=True)\n",
    "#    \n",
    "#    #LSTM output to be concatenated\n",
    "#    self.fc1 = nn.Linear(in_features=2*prm[\"lstm_hidden_size\"], out_features=16)\n",
    "#    self.dropout = nn.Dropout(p=.5)\n",
    "#    self.fc2 = nn.Linear(in_features=16, out_features=1)\n",
    "#  \n",
    "#  def forward(self, ab_tens, ab_sz, ag_tens, ag_sz):    \n",
    "#    #antibody\n",
    "#    ab_out = F.one_hot(ab_tens,len(let2ind)+1).type(torch.FloatTensor).cuda(); #self.embed_ab(ab_tens)\n",
    "#    #ab_out = pack_padded_sequence(ab_out, ab_sz.cpu(), batch_first=True, enforce_sorted=False)\n",
    "#    ab_out,(ab_hid,_) = self.rnn_ab(ab_out)\n",
    "#    #print(ab_out.shape)\n",
    "#    #ab_out,_ = pad_packed_sequence(ab_out, batch_first=True)\n",
    "#    \n",
    "#    #antigen\n",
    "#    ag_out = F.one_hot(ag_tens,len(let2ind)+1).type(torch.FloatTensor).cuda(); #self.embed_ag(ag_tens)\n",
    "#    #ag_out = pack_padded_sequence(ag_out, ag_sz.cpu(), batch_first=True, enforce_sorted=False)\n",
    "#    ag_out,(ag_hid,_) = self.rnn_ab(ag_out)\n",
    "#    #ag_out,_ = pad_packed_sequence(ag_out, batch_first=True)\n",
    "#    \n",
    "#    out = self.fc1(torch.cat([ab_out[:,-1,:],ag_out[:,-1,:]],dim=1))\n",
    "#    out = self.dropout(F.relu(out))\n",
    "#    out = self.fc2(out)\n",
    "#    return out.squeeze()\n",
    "\n",
    "\n",
    "# #test\n",
    "# rnnm = RNNModel({\"embed_dim\":32,\"lstm_hidden_size\":64}); rnnm\n",
    "# lstmdm = PandasDataModule({\"batch_size\":4})\n",
    "# dl = lstmdm.train_dataloader()\n",
    "# for n,x in enumerate(dl):\n",
    "#   rnnm.forward(*x[0])\n",
    "#   if n==2:\n",
    "#     break\n",
    "# del dl, n, x, lstmdm, rnnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d91bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNPL(pl.LightningModule):\n",
    "  \n",
    "  def __init__(self, prm):\n",
    "    super().__init__()\n",
    "    self.model = RNNModel(prm[\"model\"])   \n",
    "    self.lr = prm[\"lr\"]\n",
    "    self.save_hyperparameters()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.model.forward(*x)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    X,y = batch\n",
    "    yhat = self.forward(X)\n",
    "    return F.binary_cross_entropy_with_logits(yhat,y)\n",
    "  \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    X,y = batch\n",
    "    yhat = self.forward(X)\n",
    "    loss = F.binary_cross_entropy_with_logits(yhat,y)\n",
    "    self.log(\"valid_loss\", loss)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "# #test\n",
    "# RNNPL({\"model\":{\"embed_dim\":16,\"lstm_hidden_size\":32}, \"lr\":1E-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cbaaf",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637cdb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">266/266</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:16 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">16.58it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.693 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m266/266\u001b[0m \u001b[38;5;245m0:00:16 • 0:00:00\u001b[0m \u001b[38;5;249m16.58it/s\u001b[0m \u001b[37mloss: 0.693 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nparam: 158,753\n",
      "  current_epoch: 5\n",
      "best_model_path: /home/dnori/antibody_antigen_rnn/checkpoints/epoch=002.ckpt\n"
     ]
    }
   ],
   "source": [
    "pdm = PandasDataModule({\"batch_size\":32})\n",
    "modprm = dict(model={\"embed_dim\":16,\"lstm_hidden_size\":128}, lr=1E-3)\n",
    "rnnpl = RNNPL(modprm)\n",
    "\n",
    "checkpoint_CB = plc.ModelCheckpoint(monitor=\"valid_loss\", save_top_k=1, mode=\"min\"\n",
    "                                            , dirpath=\"checkpoints\", filename=\"{epoch:03d}\")\n",
    "earlystopping_CB = plc.early_stopping.EarlyStopping(monitor=\"valid_loss\", patience=2, mode=\"min\")\n",
    "progressbar_CB = plc.RichProgressBar()\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", strategy=\"dp\", max_epochs=20, auto_lr_find=False, auto_scale_batch_size=False, \n",
    "                     deterministic=True, logger=False, callbacks=[checkpoint_CB,earlystopping_CB,progressbar_CB])\n",
    "_ = trainer.fit(rnnpl, datamodule=pdm)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "print(f\"         nparam: {sum(p.numel() for p in rnnpl.model.parameters()):,}\")\n",
    "print(f\"  current_epoch: {trainer.current_epoch}\")\n",
    "print(f\"best_model_path: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5eda27",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf9570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnnpl = RNNPL(modprm).load_from_checkpoint(best_model_path)\n",
    "#_ = rnnpl.eval(); _ = torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186cdf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blm = BinaryLabelMetrics()\n",
    "#\n",
    "#for x in [\"train\",\"valid\",\"test\"]:\n",
    "#  print(f\"=={x} data==\")\n",
    "#  data = PandasDataset(data_dfs[x])\n",
    "#  dataDL = tudata.DataLoader(data, batch_size=128, num_workers=4, drop_last=False\n",
    "#                                    , shuffle=False, collate_fn=pad_collate)\n",
    "#  \n",
    "#  Xlst = list(); ylst = list()\n",
    "#  for X,y in dataDL:\n",
    "#    Xlst.append(torch.sigmoid(rnnpl.forward(X))) #detach().numpy()\n",
    "#    ylst.append(y) #detach().numpy()\n",
    "#  \n",
    "#  yhat = np.concatenate(Xlst); del Xlst\n",
    "#  y = np.concatenate(ylst).astype(int); del ylst\n",
    "#  blm.add_model(x, pd.DataFrame(dict(label=y,score=yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blm.plot_roc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
